# Crawling_Study
## í¬ë¡¤ë§ ê²ìŸì´ì˜ íƒˆìª¼ë© ì„±ì¥ê¸° ğŸŒ± 
<br>

### Xpath 
| File    | Link  | 
| :--------- | --------- | 
| Xpath.ipynb | [Xpath.ipynb](Xpath/Xpath.ipynb)|


```
* ë‹¨ì›ë³„ ìš”ì•½ ğŸ˜Š  

Xpath : XML ë¬¸ì„œì˜ íŠ¹ì • ìš”ì†Œë‚˜ ì†ì„±ì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ ê²½ë¡œë¥¼ ì§€ì •í•˜ëŠ” ì–¸ì–´

/ : ì ˆëŒ€ê²½ë¡œ
// : ë¬¸ì„œë‚´ ê²€ìƒ‰
//@href : href ì†ì„±ì´ ìˆëŠ” ëª¨ë“  íƒœê·¸ ì„ íƒ
//a[@href='http://google.com'] : aíƒœê·¸ì˜ href ì†ì„±ì— http://google.com ì†ì„±ê°’ì„ ê°€ì§„ ëª¨ë“  íƒœê·¸ ì„ íƒ
(//a)[3] : ë¬¸ì„œì˜ ì„¸ ë²ˆì§¸ ë§í¬ ì„ íƒ
(//table)[last()] : ë¬¸ì„œì˜ ë§ˆì§€ë§‰ í…Œì´ë¸” ì„ íƒ
(//a)[position()<3] : ë¬¸ì„œì˜ ì²˜ìŒ ë‘ ë§í¬ ì„ íƒ
//table/tr/* : ëª¨ë“  í…Œì´ë¸”ì—ì„œ ëª¨ë“  ìì‹ tr íƒœê·¸ ì„ íƒ
//div[@*] : ì†ì„±ì´ í•˜ë‚˜ë¼ë„ ìˆëŠ” div íƒœê·¸ ì„ íƒ

element_by_xpath : Xpath ì‚¬ìš© í•¨ìˆ˜ 

ì˜ˆ)  title = driver.find_element_by_xpath('//*[@id="cSub"]/div/h3')
    # ì–´ë””ì—ì„œë‚˜ (//) íƒœê·¸ê°€ cSubì¸ ì•„ì´ë””ë¥¼ ì°¾ì•„ì„œ ([@id=]) ê·¸ ì•ˆ div íƒœê·¸ì•ˆì— h3 ì°¾ì€ ì…ˆ
    print(title.text)

    # ë¬¸ì„œ ì „ì²´ì—ì„œ title ê²€ìƒ‰
    title = driver.find_element_by_xpath('//title')
    # head ë¶€ë¶„ì€ get_attributeë¡œ ë‚˜ì˜´
    print(title.get_attribute('text'))


```
<br>

### Scrapy
| File    | Link  | explanation |
| :--------- | --------- | --------- | 
| python_oop1.ipynb | [oop1.ipynb](Scrapy/python_oop1.ipynb)| ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° |
| python_oop2.ipynb | [oop2.ipynb](Scrapy/python_oop2.ipynb)| ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° |
| middlewares(ecommerce).py | [ecommerce.py](/Users/baeyuna/Documents/Crawling/Scrapy/scrapyproject_yuna/ecommerce/ecommerce/spiders/gmarket_best.py)| Scrapy gmarket í¬ë¡¤ëŸ¬ |
| middlewares(naveropenapi).py | [naveropenapi.py](/Users/baeyuna/Documents/Crawling/Scrapy/crawling_scrapy/scrapyproject/naveropenapi/naveropenapi/middlewares.py)| Scrapy ecommerce í¬ë¡¤ëŸ¬ |

```
* ë‹¨ì›ë³„ ìš”ì•½ ğŸ˜Š  

Scrapy ì¥ì 
    1. í¬ë¡¤ë§ì„ ì•ˆì •ì ìœ¼ë¡œ í•  ìˆ˜ ìˆë‹¤.
    2. í¬ë¡¤ë§ì„ ì¢€ ë” ë¹ ë¥´ê²Œ í•  ìˆ˜ ìˆë‹¤. (ë©€í‹° í”„ë¡œì„¸ì‹±)
    3. ë‹¤ì–‘í•œ í¬ë¡¤ë§ ê´€ë ¨ ê¸°ëŠ¥ (ë°ì´í„°ë¥¼ ë‹¤ì–‘í•œ í¬ë©§ìœ¼ë¡œ ì €ì¥ ê°€ëŠ¥)

Scrapy code
    1. scrapy startproject í”„ë¡œì íŠ¸ëª… 
        # í”„ë¡œì íŠ¸ ë§Œë“¤ê² ë‹¤.
        # ë§Œë“¤ì–´ì§„ í…œí”Œë¦¿ì„ ê°€ì§€ê³  í¬ë¡¤ë§ì„ ë§Œë“ ë‹¤.
    2. scrapy genspider <í¬ë¡¤ëŸ¬ì´ë¦„> <í¬ë¡¤ë§í˜ì´ì§€ì£¼ì†Œ>
        # ì•ˆìœ¼ë¡œ 2ë²ˆ ë“¤ì–´ê°€ì„œ, 
        # spider(í¬ë¡¤ëŸ¬) ì‘ì„± 
        # start_urls ìƒì„± ì‹œ ìë™ìœ¼ë¡œ https:// ê°€ ë¶™ìœ¼ë¯€ë¡œ í¬ë¡¤ë§í˜ì´ì§€ì£¼ì†Œ ì‘ì„± ì‹œ, http:// ì•ˆë¶™ì´ëŠ” ê²Œ ì¢‹ìŒ
        # https://ë§Œ ì§€ì›í•œë‹¤ë©´!! spider ì—´ì–´ì„œ 's' ë¶™ì—¬ì¤˜ì•¼í•¨.
    3. scrapy crawl í¬ë¡¤ëŸ¬ì´ë¦„
        # spider(í¬ë¡¤ëŸ¬) ì‹¤í–‰ 

Scrapy tamplet 
    scrapy.cfg
    í”„ë¡œì íŠ¸ëª…/
        __init__.py
        items.py # ì–´ë–¤ ì•„ì´í…œì„ ê°€ì ¸ì˜¬ê±´ì§€ ì„ ì–¸, í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ itemìœ¼ë¡œ ì „ë‹¬í•´ì¤Œ 
        pipelines.py 
        settings.py # 
        spiders/
            __init__.py
            í¬ë¡¤ëŸ¬ì´ë¦„.py # í¬ë¡¤ëŸ¬ì˜ parseí•¨ìˆ˜ì—ì„œ items.py itemì— ë„£ì„ ë°ì´í„° ê°€ì ¸ì˜´

scrapy shell
    scrapy shell ì£¼ì†Œ
    : í•´ë‹¹ ì£¼ì†Œì—ì„œ íŒŒì‹±í•œ ì •ë³´ ê°€ì ¸ì™€ ëª…ë ¹ì–´ í•˜ë‚˜ì”© ì ìš©í•´ ì •ë³´ ë³¼ ìˆ˜ ìˆìŒ
    : ë°”ë¡œë°”ë¡œ í™•ì¸í•  ìˆ˜ ìˆì–´, ë‚´ê°€ ì°¾ì€ ì„ íƒìê°€ ë§ëŠ”ì§€ í™•ì¸ í•  ë•Œ ì‚¬ìš©

scrapy response ì‚¬ìš©ë²•
    - response.css() : css selectorë¡œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        response.scc('head > title').get()    # í•˜ë‚˜ë§Œ ê°€ì ¸ì˜¤ê¸°
        response.scc('head > title').getall() # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì—¬ëŸ¬ê°œ ê°€ì ¸ì˜¤ê¸°
        response.scc('head > title::text').get()    # í…ìŠ¤íŠ¸ë§Œ ê°€ì ¸ì˜¤ê¸°
        response.css('div.gbest-cate ul.by-group li a::attr("href")').getall() 
                                                    # ::attr("ê°€ì ¸ì˜¤ë ¤ëŠ” ì†ì„±ê°’") 

    - response.xpath()
        response.xpath('//div[@class="best-list"]/ul/li/a/text()').getall() 
    
    - ì •ê·œí‘œí˜„ì‹ ì ìš© ê°€ëŠ¥
        response.xpath('//div[@class="best-list"]/ul/li/a/text()')[1].re('(\w+)')

scrapy ë°ì´í„° ì €ì¥í•˜ê¸°
    scrapy crawl í¬ë¡¤ëŸ¬ëª… -o ì €ì¥í• íŒŒì¼ëª… -t ì €ì¥í¬ë©§ 
    # jsonì€ í•œê¸€ì´ ê¹¨ì§ -> setting.pyì— FEED_EXPORT_ENCODING = 'utf-8' ì„¤ì •

scrapy pipeline
    - ì•„ì´í…œ ë°ì´í„° í›„ì²˜ë¦¬
        - ì¼ë¶€ ì•„ì´í…œì„ ì €ì¥í•˜ì§€ ì•Šê±°ë‚˜,
        - ì¤‘ë³µë˜ëŠ” ì•„ì´í…œì„ ì €ì¥í•˜ì§€ ì•Šê±°ë‚˜,
        - ë°ì´í„°ë² ì´ìŠ¤ ë“±ì— ì €ì¥í•˜ê±°ë‚˜,
        - íŠ¹ë³„í•œ í¬ë©§ìœ¼ë¡œ ì•„ì´í…œ ì €ì¥í•˜ê³  ì‹¶ê±°ë‚˜

    ì•„ì´í…œì´ ì €ì¥ë˜ë ¤ í•  ë•Œë§ˆë‹¤, pipelines.pyì˜ process_item í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•œë‹¤.

```
<br>

### Scrapy_Selenium

ì—¬ëŸ¬ í˜ì´ì§€ í•œë²ˆì— í¬ë¡¤ë§í•˜ëŠ” spider ë§Œë“¤ê¸°

| File    | Link  | explanation |
| :--------- | --------- | --------- | 
| gmarket_category_all | [gmarket_category_all.py](Scrapy_Selenium/scrapy2/scrapy2/spiders/gmarket_category_all.py)| ì—¬ëŸ¬ í•­ë³µ í•œë²ˆì— í¬ë¡¤ë§ |


```
* ë‹¨ì›ë³„ ìš”ì•½ ğŸ˜Š  

meta
    ì˜ˆ) meta={'maincategory_name':category_names[index]})
    # í•¨ìˆ˜ì—ì„œ ì“°ì¼ ê°’ ì „ë‹¬

# ë²”ìœ„ë¥¼ ì¢íŒ ìƒíƒœë¡œë§Œ ê°€ì ¸ì˜¤ê¸°ì— ë’¤ì´ì–´ css select ì‚¬ìš©ê°€ëŠ¥
best_items = response.css('div.best-list') 
    for index, item in enumerate(best_items[1].css('li')):

setting.py
    LOG_FILE = 'log.txt' 
    # í¬ë¡¤ë§í•œ ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì„ ê²½ìš° í„°ë¯¸ë„ ìƒìœ¼ë¡œ ë‹¤ í™•ì¸í•˜ê¸° ì–´ë ¤ì›€ 
    # íŠ¹ì •íŒŒì¼ì— ë¡œê·¸ ë„£ì–´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ í„°ë¯¸ë„ ë‚´ìš© í™•ì¸ê°€ëŠ¥

    CONCURRENT_REQUEST = 1
    # í•œë²ˆì— í¬ë¡¤ë§ í•  ìˆ˜ ìˆëŠ” ì‚¬ì´íŠ¸ 1ê°œ -> í•˜ë‚˜ í¬ë¡¤ë§í•˜ê³  ì €ì¥ -> ìˆœì„œëŒ€ë¡œ ë­í‚¹ ì €ìì¥ (ëŠë¦¼....)
    # scrapyëŠ” ê¸°ë³¸ 16ê°œ ë³‘ë ¬ì²˜ë¦¬ (=16)

    FEED_EXPORT_FIELDS =[ì¹¼ëŸ¼ ë¦¬ìŠ¤íŠ¸ ìˆœì„œëŒ€ë¡œ ì‚½ì…]
    # ì›í•˜ëŠ” ìˆœì„œëŒ€ë¡œ ë°ì´í„° ë„£ì–´ì„œ ì €ì¥í•˜ê³  ì‹¶ë‹¤.


```
<br>

### Open API

naver Open API ì‚¬ìš©
    openapi.naver.com/v1/search/shop.json?query=


| File    | Link  | explanation |
| :--------- | --------- | --------- | 
|  | [gmarket_category_all.py](Scrapy_Selenium/scrapy2/scrapy2/spiders/gmarket_category_all.py)| ì—¬ëŸ¬ í•­ë³µ í•œë²ˆì— í¬ë¡¤ë§ |


```
* ë‹¨ì›ë³„ ìš”ì•½ ğŸ˜Š  


```